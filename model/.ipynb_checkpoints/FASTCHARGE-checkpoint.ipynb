{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from models import create_mscnn_model\n",
    "import pickle as pk\n",
    "import tqdm\n",
    "# Fast charge dataset paper: https://web.mit.edu/braatzgroup/Severson_NatureEnergy_2019.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator \n",
    "class FASTCHARGESequence(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, data, batches_per_epoch=1000, batch_size=32, split_channel=False):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.batches_per_epoch = batches_per_epoch\n",
    "        self.units = self.data.keys()\n",
    "        self.data = data\n",
    "        self.split_channel = split_channel\n",
    "        D = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batches_per_epoch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        D = self.data\n",
    "      \n",
    "        X = np.zeros(shape=(self.batch_size, 9, 512, 1))\n",
    "        Y = np.zeros(shape=(self.batch_size,))\n",
    "        ncycles = len(self.units)\n",
    "        for i in range(self.batch_size):\n",
    "            unit, cycle = list(self.units)[random.randint(0, ncycles-1)]\n",
    "            Db = self.data[(unit, cycle)][:,:]\n",
    "            L = Db.shape[1] \n",
    "            \n",
    "            k = random.randint(0, L-512) \n",
    "  \n",
    "            X[i, :, :, 0] = Db[:-1, k:k+512]\n",
    "            Y[i] = max(0, Db[-1, k:k+512].min())\n",
    "            \n",
    "        return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:44:32,212\tINFO services.py:1265 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2023-03-29 15:44:33,644\tWARNING function_runner.py:559 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 1024.000: None | Iter 256.000: None | Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/2 GPUs, 0.0/13.16 GiB heap, 0.0/6.58 GiB objects (0.0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dasolma/ray_results/train_2023-03-29_15-44-33<br>Number of trials: 1/30 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  block_size</th><th style=\"text-align: right;\">  conv_activation</th><th style=\"text-align: right;\">  dense_activation</th><th style=\"text-align: right;\">  dilation_rate</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">     f1</th><th style=\"text-align: right;\">     f2</th><th style=\"text-align: right;\">     f3</th><th style=\"text-align: right;\">    fc1</th><th style=\"text-align: right;\">  kernel_size</th><th style=\"text-align: right;\">         l1</th><th style=\"text-align: right;\">        l2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  msblocks</th><th style=\"text-align: right;\">  nblocks</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_d7185cc8</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">     2.62987</td><td style=\"text-align: right;\">          2.35165</td><td style=\"text-align: right;\">            1.6933</td><td style=\"text-align: right;\">        6.48461</td><td style=\"text-align: right;\"> 0.140417</td><td style=\"text-align: right;\">4.53637</td><td style=\"text-align: right;\">3.26451</td><td style=\"text-align: right;\">13.7616</td><td style=\"text-align: right;\">179.414</td><td style=\"text-align: right;\">     0.913226</td><td style=\"text-align: right;\">2.05845e-05</td><td style=\"text-align: right;\">0.00096991</td><td style=\"text-align: right;\">0.000834118</td><td style=\"text-align: right;\">  0.553819</td><td style=\"text-align: right;\">  2.05366</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 1024.000: None | Iter 256.000: None | Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/4 CPUs, 2.0/2 GPUs, 0.0/13.16 GiB heap, 0.0/6.58 GiB objects (0.0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dasolma/ray_results/train_2023-03-29_15-44-33<br>Number of trials: 3/30 (1 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  block_size</th><th style=\"text-align: right;\">  conv_activation</th><th style=\"text-align: right;\">  dense_activation</th><th style=\"text-align: right;\">  dilation_rate</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">      f1</th><th style=\"text-align: right;\">     f2</th><th style=\"text-align: right;\">      f3</th><th style=\"text-align: right;\">    fc1</th><th style=\"text-align: right;\">  kernel_size</th><th style=\"text-align: right;\">         l1</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  msblocks</th><th style=\"text-align: right;\">  nblocks</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_d7185cc8</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">     2.62987</td><td style=\"text-align: right;\">       2.35165   </td><td style=\"text-align: right;\">          1.6933  </td><td style=\"text-align: right;\">        6.48461</td><td style=\"text-align: right;\"> 0.140417</td><td style=\"text-align: right;\"> 4.53637</td><td style=\"text-align: right;\">3.26451</td><td style=\"text-align: right;\">13.7616 </td><td style=\"text-align: right;\">179.414</td><td style=\"text-align: right;\">     0.913226</td><td style=\"text-align: right;\">2.05845e-05</td><td style=\"text-align: right;\">0.00096991 </td><td style=\"text-align: right;\">0.000834118</td><td style=\"text-align: right;\">  0.553819</td><td style=\"text-align: right;\">  2.05366</td></tr>\n",
       "<tr><td>train_d72e73a0</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">     2.05838</td><td style=\"text-align: right;\">       0.405769  </td><td style=\"text-align: right;\">          1.06952 </td><td style=\"text-align: right;\">        4.82081</td><td style=\"text-align: right;\"> 0.262106</td><td style=\"text-align: right;\">10.458  </td><td style=\"text-align: right;\">4.32203</td><td style=\"text-align: right;\"> 6.30496</td><td style=\"text-align: right;\">134.341</td><td style=\"text-align: right;\">     0.406701</td><td style=\"text-align: right;\">0.000785176</td><td style=\"text-align: right;\">0.000199674</td><td style=\"text-align: right;\">0.000519092</td><td style=\"text-align: right;\">  2.458   </td><td style=\"text-align: right;\">  1.64889</td></tr>\n",
       "<tr><td>train_d7404d32</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">     3.32656</td><td style=\"text-align: right;\">       0.00327761</td><td style=\"text-align: right;\">         -0.314195</td><td style=\"text-align: right;\">        9.97988</td><td style=\"text-align: right;\"> 0.869069</td><td style=\"text-align: right;\">13.0111 </td><td style=\"text-align: right;\">6.46693</td><td style=\"text-align: right;\"> 3.77876</td><td style=\"text-align: right;\">195.373</td><td style=\"text-align: right;\">     0.374707</td><td style=\"text-align: right;\">0.000122038</td><td style=\"text-align: right;\">0.000495177</td><td style=\"text-align: right;\">4.40446e-05</td><td style=\"text-align: right;\">  4.0457  </td><td style=\"text-align: right;\">  2.28375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:44:41,547\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.2/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 1024.000: None | Iter 256.000: None | Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/4 CPUs, 2.0/2 GPUs, 0.0/13.16 GiB heap, 0.0/6.58 GiB objects (0.0/1.0 accelerator_type:GTX)<br>Result logdir: /home/dasolma/ray_results/train_2023-03-29_15-44-33<br>Number of trials: 3/30 (1 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  block_size</th><th style=\"text-align: right;\">  conv_activation</th><th style=\"text-align: right;\">  dense_activation</th><th style=\"text-align: right;\">  dilation_rate</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">      f1</th><th style=\"text-align: right;\">     f2</th><th style=\"text-align: right;\">      f3</th><th style=\"text-align: right;\">    fc1</th><th style=\"text-align: right;\">  kernel_size</th><th style=\"text-align: right;\">         l1</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  msblocks</th><th style=\"text-align: right;\">  nblocks</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_d7185cc8</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">     2.62987</td><td style=\"text-align: right;\">       2.35165   </td><td style=\"text-align: right;\">          1.6933  </td><td style=\"text-align: right;\">        6.48461</td><td style=\"text-align: right;\"> 0.140417</td><td style=\"text-align: right;\"> 4.53637</td><td style=\"text-align: right;\">3.26451</td><td style=\"text-align: right;\">13.7616 </td><td style=\"text-align: right;\">179.414</td><td style=\"text-align: right;\">     0.913226</td><td style=\"text-align: right;\">2.05845e-05</td><td style=\"text-align: right;\">0.00096991 </td><td style=\"text-align: right;\">0.000834118</td><td style=\"text-align: right;\">  0.553819</td><td style=\"text-align: right;\">  2.05366</td></tr>\n",
       "<tr><td>train_d72e73a0</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">     2.05838</td><td style=\"text-align: right;\">       0.405769  </td><td style=\"text-align: right;\">          1.06952 </td><td style=\"text-align: right;\">        4.82081</td><td style=\"text-align: right;\"> 0.262106</td><td style=\"text-align: right;\">10.458  </td><td style=\"text-align: right;\">4.32203</td><td style=\"text-align: right;\"> 6.30496</td><td style=\"text-align: right;\">134.341</td><td style=\"text-align: right;\">     0.406701</td><td style=\"text-align: right;\">0.000785176</td><td style=\"text-align: right;\">0.000199674</td><td style=\"text-align: right;\">0.000519092</td><td style=\"text-align: right;\">  2.458   </td><td style=\"text-align: right;\">  1.64889</td></tr>\n",
       "<tr><td>train_d7404d32</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">     3.32656</td><td style=\"text-align: right;\">       0.00327761</td><td style=\"text-align: right;\">         -0.314195</td><td style=\"text-align: right;\">        9.97988</td><td style=\"text-align: right;\"> 0.869069</td><td style=\"text-align: right;\">13.0111 </td><td style=\"text-align: right;\">6.46693</td><td style=\"text-align: right;\"> 3.77876</td><td style=\"text-align: right;\">195.373</td><td style=\"text-align: right;\">     0.374707</td><td style=\"text-align: right;\">0.000122038</td><td style=\"text-align: right;\">0.000495177</td><td style=\"text-align: right;\">4.40446e-05</td><td style=\"text-align: right;\">  4.0457  </td><td style=\"text-align: right;\">  2.28375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m 2023-03-29 15:44:41,562\tERROR worker.py:428 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"python/ray/_raylet.pyx\", line 488, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"python/ray/_raylet.pyx\", line 525, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"python/ray/_raylet.pyx\", line 532, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"python/ray/_raylet.pyx\", line 536, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/tune/trainable.py\", line 237, in train\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 362, in step\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/queue.py\", line 179, in get\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     self.not_empty.wait(remaining)\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/threading.py\", line 300, in wait\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/worker.py\", line 425, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=26272)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m 2023-03-29 15:44:41,567\tERROR worker.py:428 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"python/ray/_raylet.pyx\", line 640, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"python/ray/_raylet.pyx\", line 488, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"python/ray/_raylet.pyx\", line 525, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"python/ray/_raylet.pyx\", line 532, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"python/ray/_raylet.pyx\", line 536, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/tune/trainable.py\", line 237, in train\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 362, in step\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/queue.py\", line 179, in get\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     self.not_empty.wait(remaining)\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/threading.py\", line 300, in wait\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m   File \"/opt/anaconda/lib/python3.7/site-packages/ray/worker.py\", line 425, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=26271)\u001b[0m SystemExit: 1\n",
      "2023-03-29 15:44:41,765\tERROR tune.py:557 -- Trials did not complete: [train_d7185cc8, train_d72e73a0, train_d7404d32]\n",
      "2023-03-29 15:44:41,765\tINFO tune.py:561 -- Total run time: 8.12 seconds (7.01 seconds for the tuning loop).\n",
      "2023-03-29 15:44:41,766\tWARNING tune.py:566 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=4, num_gpus=2)\n",
    "\n",
    "\n",
    "\n",
    "def train(config):\n",
    "     \n",
    "\n",
    "    \n",
    "    train_units = ['b1c25', 'b1c17', 'b1c15', 'b1c27', 'b1c41', 'b1c23', 'b1c22', 'b1c46', 'b1c11',\n",
    "                   'b1c35', 'b1c28', 'b1c20', 'b1c30', 'b1c40', 'b1c43', 'b1c3', 'b1c13', 'b1c32', \n",
    "                   'b1c6', 'b1c1', 'b1c34', 'b1c18', 'b1c5', 'b1c39', 'b1c44', 'b1c10', 'b1c2', 'b1c0', \n",
    "                   'b1c31', 'b1c19', 'b1c37', 'b1c38']\n",
    "    test_units = ['b1c12', 'b1c14', 'b1c16', 'b1c21', 'b1c24', 'b1c26', 'b1c29', 'b1c33', 'b1c36', \n",
    "                  'b1c4', 'b1c42', 'b1c45', 'b1c7', 'b1c8', 'b1c9']\n",
    "  \n",
    "    X = pk.load(open('/home/dasolma/papers/xai/data/fast_charge.pk', 'rb'))\n",
    "\n",
    "    X_train = {k: v for k, v in X.items() if k[0] in train_units}\n",
    "    X_test =  {k: v for k, v in X.items() if k[0] in test_units}\n",
    "    \n",
    "    def norm(values, i, _min, _max):\n",
    "        values[i] = (values[i] - _min) / (_max - _min)\n",
    "        return values\n",
    "\n",
    "    for i in range(9):\n",
    "        values = np.hstack([d[i] for k, d in X_train.items()])\n",
    "        _min, _max = values.min(), values.max()\n",
    "\n",
    "        X_train = {k: norm(v, i, _min, _max) for k, v in X_train.items()}\n",
    "        X_test = {k: norm(v, i, _min, _max) for k, v in X_test.items()}\n",
    "\n",
    "    gen_train = FASTCHARGESequence(X_train, batches_per_epoch=2500)\n",
    "    gen_val = FASTCHARGESequence(X_test, batches_per_epoch=5000)\n",
    "    \n",
    "    epochs = config.pop(\"epochs\")\n",
    "    \n",
    "    m = create_mscnn_model((9,512,1),**config)\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "    rlr = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "    history = m.fit(gen_train, validation_data=gen_val,\n",
    "                    batch_size=32, epochs=epochs, verbose=0,\n",
    "                   callbacks=[es, rlr])\n",
    "    history = history.history\n",
    "    tune.report(score=history['val_loss'][-1])\n",
    "    \n",
    "\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "space = {\n",
    "    \"block_size\": (1.51, 4.5),\n",
    "    \"msblocks\": (-0.51, 4.5),\n",
    "    \"nblocks\": (1.51, 4.5),\n",
    "    \"l1\": (0, 1e-3),\n",
    "    \"l2\": (0, 1e-3),\n",
    "    \"dropout\": (0, 0.9),\n",
    "    \"lr\": (1e-5, 1e-3),\n",
    "    \"fc1\": (64, 256),\n",
    "    \"conv_activation\": (-0.51, 2.5),\n",
    "    \"dense_activation\": (-0.51, 2.5),\n",
    "    \"dilation_rate\": (0.51, 10.49),\n",
    "    \"kernel_size\": (-0.51, 1.5),\n",
    "    \"f1\": (2.51, 15.5),\n",
    "    \"f2\": (2.51, 15.5),\n",
    "    \"f3\": (2.51, 15.5),\n",
    "}\n",
    "\n",
    "\n",
    "bayesopt = BayesOptSearch(space=space, mode=\"min\", metric=\"score\")\n",
    "scheduler=ASHAScheduler(metric=\"score\", mode=\"min\", max_t=3600, time_attr='training_iteration')\n",
    "\n",
    "analysis = tune.run(\n",
    "    train,\n",
    "    config={\n",
    "        \"epochs\": 100,\n",
    "        \"input_folding_size\": 128,\n",
    "    },\n",
    "    resources_per_trial={'gpu': 1},\n",
    "    num_samples=30,\n",
    "    search_alg=bayesopt,\n",
    "    log_to_file=False,\n",
    "    scheduler=scheduler\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from ray results directory....\n",
    "\n",
    "config = {\n",
    "  \"block_size\": 2.672145096171551,\n",
    "  \"conv_activation\": 0.30676058563942665,\n",
    "  \"dense_activation\": 1.9844999025473073,\n",
    "  \"dilation_rate\": 4.070398200402021,\n",
    "  \"dropout\": 0.2528410587186427,\n",
    "  \"epochs\": 100,\n",
    "  \"fc1\": 168.1976479663837,\n",
    "  \"fc2\": 0.14092422497476265,\n",
    "  \"input_folding_size\": 128,\n",
    "  \"kernel_size\": 1.1024159313156197,\n",
    "  \"l1\": 7.455064367977083e-05,\n",
    "  \"l2\": 0.0009868869366005174,\n",
    "  \"lr\": 0.0007745223216036909,\n",
    "  \"msblocks\": 0,\n",
    "  \"nblocks\": 3.3028755693213476\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = config.pop(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pk.load(open('../data/fast_charge.pk', 'rb'))\n",
    "\n",
    "\n",
    "train_units = ['b1c25', 'b1c17', 'b1c15', 'b1c27', 'b1c41', 'b1c23', 'b1c22', 'b1c46', 'b1c11',\n",
    "               'b1c35', 'b1c28', 'b1c20', 'b1c30', 'b1c40', 'b1c43', 'b1c3', 'b1c13', 'b1c32', \n",
    "               'b1c6', 'b1c1', 'b1c34', 'b1c18', 'b1c5', 'b1c39', 'b1c44', 'b1c10', 'b1c2', 'b1c0', \n",
    "               'b1c31', 'b1c19', 'b1c37', 'b1c38']\n",
    "test_units = ['b1c12', 'b1c14', 'b1c16', 'b1c21', 'b1c24', 'b1c26', 'b1c29', 'b1c33', 'b1c36', \n",
    "              'b1c4', 'b1c42', 'b1c45', 'b1c7', 'b1c8', 'b1c9']\n",
    "\n",
    "X_train = {k: v for k, v in X.items() if k[0] in train_units}\n",
    "X_test =  {k: v for k, v in X.items() if k[0] in test_units}\n",
    "\n",
    "def norm(values, i, _min, _max):\n",
    "    values[i] = (values[i] - _min) / (_max - _min)\n",
    "    return values\n",
    "\n",
    "for i in range(9):\n",
    "    values = np.hstack([d[i] for k, d in X_train.items()])\n",
    "    _min, _max = values.min(), values.max()\n",
    "    \n",
    "    X_train = {k: norm(v, i, _min, _max) for k, v in X_train.items()}\n",
    "    X_test = {k: norm(v, i, _min, _max) for k, v in X_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 111s 44ms/step - loss: 123498.2812 - NASA_score: inf - Score: inf - MAE: 266.9903 - val_loss: 152157.7031 - val_NASA_score: inf - val_Score: inf - val_MAE: 299.0349 - lr: 7.7452e-04\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 114s 46ms/step - loss: 101659.8906 - NASA_score: inf - Score: inf - MAE: 233.5676 - val_loss: 128717.8906 - val_NASA_score: inf - val_Score: inf - val_MAE: 268.6147 - lr: 7.7452e-04\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 116s 46ms/step - loss: 87543.4531 - NASA_score: inf - Score: inf - MAE: 212.0189 - val_loss: 110755.3438 - val_NASA_score: inf - val_Score: inf - val_MAE: 246.6435 - lr: 7.7452e-04\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 74344.3750 - NASA_score: inf - Score: inf - MAE: 194.5747 - val_loss: 96605.4219 - val_NASA_score: inf - val_Score: inf - val_MAE: 229.8529 - lr: 7.7452e-04\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 65161.3945 - NASA_score: inf - Score: inf - MAE: 183.2249 - val_loss: 85149.0078 - val_NASA_score: inf - val_Score: inf - val_MAE: 217.5993 - lr: 7.7452e-04\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 60113.5469 - NASA_score: inf - Score: inf - MAE: 178.4108 - val_loss: 77505.5625 - val_NASA_score: inf - val_Score: inf - val_MAE: 209.9579 - lr: 7.7452e-04\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 56023.0469 - NASA_score: inf - Score: inf - MAE: 172.4724 - val_loss: 65863.3750 - val_NASA_score: inf - val_Score: inf - val_MAE: 186.4625 - lr: 7.7452e-04\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 41348.8555 - NASA_score: inf - Score: inf - MAE: 128.0485 - val_loss: 54294.6445 - val_NASA_score: 994993378120594931914964920696832.0000 - val_Score: 497496689060297465957482460348416.0000 - val_MAE: 159.2206 - lr: 7.7452e-04\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 34836.6055 - NASA_score: inf - Score: inf - MAE: 113.3337 - val_loss: 45989.0703 - val_NASA_score: 27410615838806883031575722721280.0000 - val_Score: 13705307919403441515787861360640.0000 - val_MAE: 142.6205 - lr: 7.7452e-04\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 30904.0605 - NASA_score: inf - Score: inf - MAE: 105.7509 - val_loss: 38489.0078 - val_NASA_score: 891865000586805306343775272960.0000 - val_Score: 445932500293402653171887636480.0000 - val_MAE: 124.6787 - lr: 7.7452e-04\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 27309.0977 - NASA_score: inf - Score: inf - MAE: 101.2342 - val_loss: 33812.9297 - val_NASA_score: 33375539985356188116653703168.0000 - val_Score: 16687769992678094058326851584.0000 - val_MAE: 118.5502 - lr: 7.7452e-04\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 24464.9082 - NASA_score: inf - Score: inf - MAE: 97.3925 - val_loss: 28946.7363 - val_NASA_score: 1322665187501432331350057156608.0000 - val_Score: 661332593750716165675028578304.0000 - val_MAE: 107.6429 - lr: 7.7452e-04\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 22494.8906 - NASA_score: inf - Score: inf - MAE: 94.0453 - val_loss: 26139.9746 - val_NASA_score: 428890764140409444139156897792.0000 - val_Score: 214445382070204722069578448896.0000 - val_MAE: 104.9831 - lr: 7.7452e-04\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 19830.3145 - NASA_score: inf - Score: inf - MAE: 89.6012 - val_loss: 26855.8008 - val_NASA_score: 2907749892045295159607296.0000 - val_Score: 1453874946022647579803648.0000 - val_MAE: 115.8746 - lr: 7.7452e-04\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 17934.0508 - NASA_score: inf - Score: inf - MAE: 85.5045 - val_loss: 34402.3477 - val_NASA_score: 30188715283023104728758768107520.0000 - val_Score: 15094357641511552364379384053760.0000 - val_MAE: 118.3029 - lr: 7.7452e-04\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 16106.5186 - NASA_score: inf - Score: inf - MAE: 82.2024 - val_loss: 18520.2598 - val_NASA_score: 10852143878089589391360.0000 - val_Score: 5426071939044794695680.0000 - val_MAE: 88.7563 - lr: 7.7452e-04\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 14938.6260 - NASA_score: inf - Score: inf - MAE: 80.4416 - val_loss: 16086.9854 - val_NASA_score: 4728379544976922224099328.0000 - val_Score: 2364189772488461112049664.0000 - val_MAE: 83.5109 - lr: 7.7452e-04\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 13629.8643 - NASA_score: inf - Score: inf - MAE: 77.2401 - val_loss: 16449.8027 - val_NASA_score: 69254357633196756125614080.0000 - val_Score: 34627178816598378062807040.0000 - val_MAE: 85.1570 - lr: 7.7452e-04\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 12468.4824 - NASA_score: inf - Score: inf - MAE: 75.0371 - val_loss: 16892.5508 - val_NASA_score: 186876989683041042432.0000 - val_Score: 93438494841520521216.0000 - val_MAE: 88.6531 - lr: 7.7452e-04\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 11592.7217 - NASA_score: inf - Score: inf - MAE: 72.6005 - val_loss: 31659.7852 - val_NASA_score: 13840467034962176672149186543616.0000 - val_Score: 6920233517481088336074593271808.0000 - val_MAE: 110.8769 - lr: 7.7452e-04\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 10294.2910 - NASA_score: inf - Score: inf - MAE: 68.1213 - val_loss: 13222.4814 - val_NASA_score: 110451941945540345856.0000 - val_Score: 55225970972770172928.0000 - val_MAE: 74.9587 - lr: 7.7452e-05\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 10480.0342 - NASA_score: inf - Score: inf - MAE: 67.6774 - val_loss: 12430.0986 - val_NASA_score: 2618821791217713414144.0000 - val_Score: 1309410895608856707072.0000 - val_MAE: 72.1575 - lr: 7.7452e-05\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9932.2012 - NASA_score: inf - Score: inf - MAE: 66.2841 - val_loss: 11998.0156 - val_NASA_score: 514219140681442525184.0000 - val_Score: 257109570340721262592.0000 - val_MAE: 71.4380 - lr: 7.7452e-05\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 10138.3633 - NASA_score: inf - Score: inf - MAE: 66.5782 - val_loss: 11697.9111 - val_NASA_score: 233277435906350907392.0000 - val_Score: 116638717953175453696.0000 - val_MAE: 70.8220 - lr: 7.7452e-05\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9898.3369 - NASA_score: inf - Score: inf - MAE: 66.0882 - val_loss: 11596.9404 - val_NASA_score: 723023787514243579904.0000 - val_Score: 361511893757121789952.0000 - val_MAE: 70.0379 - lr: 7.7452e-05\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9750.4336 - NASA_score: inf - Score: inf - MAE: 65.1803 - val_loss: 11100.8203 - val_NASA_score: 907463362228644741120.0000 - val_Score: 453731681114322370560.0000 - val_MAE: 67.6920 - lr: 7.7452e-05\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9431.7324 - NASA_score: inf - Score: inf - MAE: 64.5744 - val_loss: 11417.8848 - val_NASA_score: 849901729491315589120.0000 - val_Score: 424950864745657794560.0000 - val_MAE: 69.1331 - lr: 7.7452e-05\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9607.4355 - NASA_score: inf - Score: inf - MAE: 64.6243 - val_loss: 10802.7520 - val_NASA_score: 6367797702076055683072.0000 - val_Score: 3183898851038027841536.0000 - val_MAE: 67.4385 - lr: 7.7452e-05\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9343.7959 - NASA_score: inf - Score: inf - MAE: 64.1324 - val_loss: 11520.8652 - val_NASA_score: 12363953278759731200.0000 - val_Score: 6181976639379865600.0000 - val_MAE: 71.0112 - lr: 7.7452e-05\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 9282.2344 - NASA_score: inf - Score: inf - MAE: 63.7223 - val_loss: 10640.0635 - val_NASA_score: 265075136259772383232.0000 - val_Score: 132537568129886191616.0000 - val_MAE: 67.0592 - lr: 7.7452e-05\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 119s 47ms/step - loss: 9113.1748 - NASA_score: inf - Score: inf - MAE: 63.3130 - val_loss: 10452.0977 - val_NASA_score: 138899500737872527360.0000 - val_Score: 69449750368936263680.0000 - val_MAE: 66.8259 - lr: 7.7452e-05\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8809.9326 - NASA_score: inf - Score: inf - MAE: 62.4382 - val_loss: 10495.0801 - val_NASA_score: 130094769952316719104.0000 - val_Score: 65047384976158359552.0000 - val_MAE: 66.5965 - lr: 7.7452e-05\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 8833.0146 - NASA_score: inf - Score: inf - MAE: 62.3541 - val_loss: 10223.8564 - val_NASA_score: 22647426048604504064.0000 - val_Score: 11323713024302252032.0000 - val_MAE: 65.0547 - lr: 7.7452e-05\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8716.7129 - NASA_score: inf - Score: inf - MAE: 62.1636 - val_loss: 10861.7441 - val_NASA_score: 693302141035923636224.0000 - val_Score: 346651070517961818112.0000 - val_MAE: 67.9863 - lr: 7.7452e-05\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8726.5908 - NASA_score: inf - Score: inf - MAE: 61.8927 - val_loss: 10544.6631 - val_NASA_score: 1048638599148339200.0000 - val_Score: 524319299574169600.0000 - val_MAE: 67.9817 - lr: 7.7452e-05\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8833.1426 - NASA_score: inf - Score: inf - MAE: 62.2693 - val_loss: 9775.3252 - val_NASA_score: 7151236821194637312.0000 - val_Score: 3575618410597318656.0000 - val_MAE: 65.2805 - lr: 7.7452e-05\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8551.1084 - NASA_score: inf - Score: inf - MAE: 61.5230 - val_loss: 9929.4170 - val_NASA_score: 11843447772705456128.0000 - val_Score: 5921723886352728064.0000 - val_MAE: 65.1241 - lr: 7.7452e-05\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8508.1885 - NASA_score: inf - Score: inf - MAE: 61.3526 - val_loss: 9343.1123 - val_NASA_score: 41384065159070220288.0000 - val_Score: 20692032579535110144.0000 - val_MAE: 63.7437 - lr: 7.7452e-05\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8578.3564 - NASA_score: inf - Score: inf - MAE: 61.5831 - val_loss: 9357.6396 - val_NASA_score: 6245254083314188288.0000 - val_Score: 3122627041657094144.0000 - val_MAE: 63.7575 - lr: 7.7452e-05\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8412.0000 - NASA_score: inf - Score: inf - MAE: 60.9350 - val_loss: 9551.1328 - val_NASA_score: 506513773914226688.0000 - val_Score: 253256886957113344.0000 - val_MAE: 64.5979 - lr: 7.7452e-05\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8285.0010 - NASA_score: inf - Score: inf - MAE: 60.5202 - val_loss: 10034.6064 - val_NASA_score: 1049940928889998016512.0000 - val_Score: 524970464444999008256.0000 - val_MAE: 64.7472 - lr: 7.7452e-05\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8219.5166 - NASA_score: inf - Score: inf - MAE: 60.2868 - val_loss: 9261.5430 - val_NASA_score: 4196931540732608512.0000 - val_Score: 2098465770366304256.0000 - val_MAE: 63.1767 - lr: 7.7452e-06\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8244.8037 - NASA_score: inf - Score: inf - MAE: 60.0343 - val_loss: 9228.4121 - val_NASA_score: 5633044359701069824.0000 - val_Score: 2816522179850534912.0000 - val_MAE: 63.1457 - lr: 7.7452e-06\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 7949.6528 - NASA_score: inf - Score: inf - MAE: 59.4427 - val_loss: 9111.9756 - val_NASA_score: 10276355631078178816.0000 - val_Score: 5138177815539089408.0000 - val_MAE: 62.9042 - lr: 7.7452e-06\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8205.5020 - NASA_score: inf - Score: inf - MAE: 59.9993 - val_loss: 9039.7275 - val_NASA_score: 4361223316933967872.0000 - val_Score: 2180611658466983936.0000 - val_MAE: 62.6881 - lr: 7.7452e-06\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8163.6831 - NASA_score: inf - Score: inf - MAE: 60.0250 - val_loss: 9051.0312 - val_NASA_score: 4576720174274576384.0000 - val_Score: 2288360087137288192.0000 - val_MAE: 62.6313 - lr: 7.7452e-06\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8186.6855 - NASA_score: inf - Score: inf - MAE: 60.0071 - val_loss: 9065.8564 - val_NASA_score: 6185667699914309632.0000 - val_Score: 3092833849957154816.0000 - val_MAE: 62.6852 - lr: 7.7452e-06\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8111.9111 - NASA_score: inf - Score: inf - MAE: 59.8024 - val_loss: 9110.4160 - val_NASA_score: 2106871949077512192.0000 - val_Score: 1053435974538756096.0000 - val_MAE: 63.1458 - lr: 7.7452e-06\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8046.7969 - NASA_score: inf - Score: inf - MAE: 59.7579 - val_loss: 9026.1201 - val_NASA_score: 3058328426298474496.0000 - val_Score: 1529164213149237248.0000 - val_MAE: 62.7857 - lr: 7.7452e-07\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8070.9312 - NASA_score: inf - Score: inf - MAE: 59.6481 - val_loss: 9017.5645 - val_NASA_score: 3271818674918391808.0000 - val_Score: 1635909337459195904.0000 - val_MAE: 62.6963 - lr: 7.7452e-07\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8140.7129 - NASA_score: inf - Score: inf - MAE: 59.7281 - val_loss: 9074.8135 - val_NASA_score: 5338557762387312640.0000 - val_Score: 2669278881193656320.0000 - val_MAE: 62.6459 - lr: 7.7452e-07\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8158.7231 - NASA_score: inf - Score: inf - MAE: 59.8166 - val_loss: 9088.1758 - val_NASA_score: 2465085553142398976.0000 - val_Score: 1232542776571199488.0000 - val_MAE: 62.9099 - lr: 7.7452e-07\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8147.3047 - NASA_score: inf - Score: inf - MAE: 59.7394 - val_loss: 9016.0566 - val_NASA_score: 2355251763231064064.0000 - val_Score: 1177625881615532032.0000 - val_MAE: 62.5255 - lr: 7.7452e-07\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8122.5674 - NASA_score: inf - Score: inf - MAE: 59.7190 - val_loss: 8981.4775 - val_NASA_score: 1687794741418131456.0000 - val_Score: 843897370709065728.0000 - val_MAE: 62.4800 - lr: 7.7452e-07\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 7962.7319 - NASA_score: inf - Score: inf - MAE: 59.4395 - val_loss: 8981.6836 - val_NASA_score: 4928124915145506816.0000 - val_Score: 2464062457572753408.0000 - val_MAE: 62.3232 - lr: 7.7452e-07\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8175.5088 - NASA_score: inf - Score: inf - MAE: 59.5413 - val_loss: 9085.6064 - val_NASA_score: 3656950385215537152.0000 - val_Score: 1828475192607768576.0000 - val_MAE: 62.8868 - lr: 7.7452e-07\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8186.0278 - NASA_score: inf - Score: inf - MAE: 59.7228 - val_loss: 9121.3916 - val_NASA_score: 4079011117676888064.0000 - val_Score: 2039505558838444032.0000 - val_MAE: 62.7708 - lr: 7.7452e-07\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 8163.2944 - NASA_score: inf - Score: inf - MAE: 59.6908 - val_loss: 9021.7783 - val_NASA_score: 2726335288338022400.0000 - val_Score: 1363167644169011200.0000 - val_MAE: 62.6368 - lr: 7.7452e-08\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8235.9795 - NASA_score: inf - Score: inf - MAE: 59.8699 - val_loss: 8956.6143 - val_NASA_score: 3287969676096700416.0000 - val_Score: 1643984838048350208.0000 - val_MAE: 62.3322 - lr: 7.7452e-08\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 7985.5400 - NASA_score: inf - Score: inf - MAE: 59.6369 - val_loss: 9038.0908 - val_NASA_score: 1869630737469145088.0000 - val_Score: 934815368734572544.0000 - val_MAE: 62.6937 - lr: 7.7452e-08\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8057.2617 - NASA_score: inf - Score: inf - MAE: 59.7391 - val_loss: 9118.3867 - val_NASA_score: 5483655913858400256.0000 - val_Score: 2741827956929200128.0000 - val_MAE: 63.0014 - lr: 7.7452e-08\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8180.2969 - NASA_score: inf - Score: inf - MAE: 59.7842 - val_loss: 9026.2979 - val_NASA_score: 1776627034605223936.0000 - val_Score: 888313517302611968.0000 - val_MAE: 62.6284 - lr: 7.7452e-08\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8054.2886 - NASA_score: inf - Score: inf - MAE: 59.4510 - val_loss: 9035.1875 - val_NASA_score: 4352539923853606912.0000 - val_Score: 2176269961926803456.0000 - val_MAE: 62.7839 - lr: 7.7452e-09\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8210.6963 - NASA_score: inf - Score: inf - MAE: 59.8243 - val_loss: 9091.1436 - val_NASA_score: 2318874970781908992.0000 - val_Score: 1159437485390954496.0000 - val_MAE: 62.9795 - lr: 7.7452e-09\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8086.7871 - NASA_score: inf - Score: inf - MAE: 59.6554 - val_loss: 8959.9629 - val_NASA_score: 2903579311514583040.0000 - val_Score: 1451789655757291520.0000 - val_MAE: 62.5359 - lr: 7.7452e-09\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 7979.4126 - NASA_score: inf - Score: inf - MAE: 59.2838 - val_loss: 9046.2637 - val_NASA_score: 6435649365070577664.0000 - val_Score: 3217824682535288832.0000 - val_MAE: 62.7893 - lr: 7.7452e-10\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 8080.2090 - NASA_score: inf - Score: inf - MAE: 59.7333 - val_loss: 9072.4414 - val_NASA_score: 4641241990493634560.0000 - val_Score: 2320620995246817280.0000 - val_MAE: 62.7302 - lr: 7.7452e-10\n"
     ]
    }
   ],
   "source": [
    "gen_train = FASTCHARGESequence(X_train, batches_per_epoch=2500)\n",
    "gen_val = FASTCHARGESequence(X_test, batches_per_epoch=5000)\n",
    "\n",
    "\n",
    "m = create_mscnn_model((9,512,1),**config)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "rlr = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "history = m.fit(gen_train, validation_data=gen_val,\n",
    "                batch_size=32, epochs=epochs, \n",
    "               callbacks=[es, rlr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 110s 44ms/step - loss: 9251.0928 - NASA_score: inf - Score: inf - MAE: 65.7001 - val_loss: 13295.7188 - val_NASA_score: 6236598837731498393600.0000 - val_Score: 3118299418865749196800.0000 - val_MAE: 76.3811 - lr: 7.7452e-04\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 113s 45ms/step - loss: 8735.4893 - NASA_score: inf - Score: inf - MAE: 64.5578 - val_loss: 12095.7012 - val_NASA_score: 338076973432185791971328.0000 - val_Score: 169038486716092895985664.0000 - val_MAE: 72.8936 - lr: 7.7452e-04\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 115s 46ms/step - loss: 8637.8721 - NASA_score: inf - Score: inf - MAE: 64.3215 - val_loss: 10973.0498 - val_NASA_score: 12000257790094218362880.0000 - val_Score: 6000128895047109181440.0000 - val_MAE: 70.4429 - lr: 7.7452e-04\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 115s 46ms/step - loss: 8258.5088 - NASA_score: inf - Score: inf - MAE: 63.2333 - val_loss: 10279.4805 - val_NASA_score: 75456219663755640832.0000 - val_Score: 37728109831877820416.0000 - val_MAE: 65.0344 - lr: 7.7452e-04\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 116s 46ms/step - loss: 7860.3135 - NASA_score: inf - Score: inf - MAE: 61.6253 - val_loss: 12414.1709 - val_NASA_score: 36837887253151744.0000 - val_Score: 18418943626575872.0000 - val_MAE: 76.2140 - lr: 7.7452e-04\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 116s 47ms/step - loss: 7663.2695 - NASA_score: inf - Score: inf - MAE: 61.1007 - val_loss: 11058.7578 - val_NASA_score: 851121149459170328576.0000 - val_Score: 425560574729585164288.0000 - val_MAE: 70.6033 - lr: 7.7452e-04\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 116s 47ms/step - loss: 7340.4966 - NASA_score: inf - Score: inf - MAE: 59.4248 - val_loss: 10940.7607 - val_NASA_score: 8230874947927953161322496.0000 - val_Score: 4115437473963976580661248.0000 - val_MAE: 69.3620 - lr: 7.7452e-04\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6525.9614 - NASA_score: inf - Score: inf - MAE: 55.5703 - val_loss: 7753.7104 - val_NASA_score: 1025385860956160.0000 - val_Score: 512692930478080.0000 - val_MAE: 60.5286 - lr: 7.7452e-05\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6289.1641 - NASA_score: inf - Score: inf - MAE: 54.7193 - val_loss: 8042.8838 - val_NASA_score: 23019107003662336.0000 - val_Score: 11509553501831168.0000 - val_MAE: 60.6730 - lr: 7.7452e-05\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6276.4429 - NASA_score: inf - Score: inf - MAE: 54.3986 - val_loss: 7465.5938 - val_NASA_score: 5155414064758784.0000 - val_Score: 2577707032379392.0000 - val_MAE: 59.2420 - lr: 7.7452e-05\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6199.9961 - NASA_score: inf - Score: inf - MAE: 53.8641 - val_loss: 8045.6631 - val_NASA_score: 11844484715249664.0000 - val_Score: 5922242357624832.0000 - val_MAE: 60.6749 - lr: 7.7452e-05\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6169.6025 - NASA_score: inf - Score: inf - MAE: 53.6687 - val_loss: 7792.5840 - val_NASA_score: 32810940948807680.0000 - val_Score: 16405470474403840.0000 - val_MAE: 59.6352 - lr: 7.7452e-05\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6031.5029 - NASA_score: inf - Score: inf - MAE: 53.4341 - val_loss: 7384.9775 - val_NASA_score: 13941661411311616.0000 - val_Score: 6970830705655808.0000 - val_MAE: 58.4619 - lr: 7.7452e-05\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6128.4478 - NASA_score: inf - Score: inf - MAE: 53.3881 - val_loss: 7511.5625 - val_NASA_score: 39047944279687168.0000 - val_Score: 19523972139843584.0000 - val_MAE: 59.0435 - lr: 7.7452e-05\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 5949.9131 - NASA_score: 15009747898487608676318183424.0000 - Score: 7504873949243804338159091712.0000 - MAE: 52.9922 - val_loss: 7713.6680 - val_NASA_score: 99530068878950400.0000 - val_Score: 49765034439475200.0000 - val_MAE: 59.3092 - lr: 7.7452e-05\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 6020.3232 - NASA_score: inf - Score: inf - MAE: 52.7987 - val_loss: 7684.2095 - val_NASA_score: 1010645593325830144.0000 - val_Score: 505322796662915072.0000 - val_MAE: 59.1095 - lr: 7.7452e-05\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 117s 47ms/step - loss: 5829.8423 - NASA_score: inf - Score: inf - MAE: 52.4962 - val_loss: 7005.4814 - val_NASA_score: 2844387994238976.0000 - val_Score: 1422193997119488.0000 - val_MAE: 57.1202 - lr: 7.7452e-06\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 118s 47ms/step - loss: 5906.8760 - NASA_score: inf - Score: inf - MAE: 52.5995 - val_loss: 7044.6440 - val_NASA_score: 2317584754016256.0000 - val_Score: 1158792377008128.0000 - val_MAE: 57.2669 - lr: 7.7452e-06\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 120s 48ms/step - loss: 5791.1294 - NASA_score: inf - Score: inf - MAE: 52.0859 - val_loss: 7123.6670 - val_NASA_score: 8342168666112000.0000 - val_Score: 4171084333056000.0000 - val_MAE: 57.7588 - lr: 7.7452e-06\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 123s 49ms/step - loss: 5914.4434 - NASA_score: inf - Score: inf - MAE: 52.4232 - val_loss: 7147.4302 - val_NASA_score: 8308402706972672.0000 - val_Score: 4154201353486336.0000 - val_MAE: 57.8961 - lr: 7.7452e-06\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 123s 49ms/step - loss: 5772.4468 - NASA_score: inf - Score: inf - MAE: 51.9693 - val_loss: 7156.6802 - val_NASA_score: 10006653176905728.0000 - val_Score: 5003326588452864.0000 - val_MAE: 57.7730 - lr: 7.7452e-07\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 122s 49ms/step - loss: 5888.4419 - NASA_score: inf - Score: inf - MAE: 52.3729 - val_loss: 7074.1240 - val_NASA_score: 6593943567335424.0000 - val_Score: 3296971783667712.0000 - val_MAE: 57.6429 - lr: 7.7452e-07\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 121s 48ms/step - loss: 5966.9814 - NASA_score: inf - Score: inf - MAE: 52.6895 - val_loss: 7180.2402 - val_NASA_score: 7891390373560320.0000 - val_Score: 3945695186780160.0000 - val_MAE: 57.8809 - lr: 7.7452e-07\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 121s 49ms/step - loss: 5958.9985 - NASA_score: inf - Score: inf - MAE: 52.5973 - val_loss: 7183.0430 - val_NASA_score: 7143296191168512.0000 - val_Score: 3571648095584256.0000 - val_MAE: 57.9615 - lr: 7.7452e-08\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 123s 49ms/step - loss: 5867.5967 - NASA_score: inf - Score: inf - MAE: 51.9796 - val_loss: 7188.5928 - val_NASA_score: 19331926972170240.0000 - val_Score: 9665963486085120.0000 - val_MAE: 57.8818 - lr: 7.7452e-08\n"
     ]
    }
   ],
   "source": [
    "from scoring import *\n",
    "lr = 0.0007745223216036909\n",
    "m.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(lr=lr), \n",
    "                  metrics=[NASAScore(), PHM21Score(), tf.keras.metrics.MeanAbsoluteError(name=\"MAE\")])\n",
    "  \n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "rlr = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "history = m.fit(gen_train, validation_data=gen_val,\n",
    "                batch_size=32, epochs=epochs, \n",
    "               callbacks=[es, rlr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('../data/models/fast_charge/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import *\n",
    "from models import SplitTS\n",
    "m = tf.keras.models.load_model('../data/models/fast_charge/model.h5', \n",
    "                                   custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU,\n",
    "                                                  'NASAScore': NASAScore,\n",
    "                                                  'SplitTS': SplitTS,\n",
    "                                                  'PHM21Score': PHM21Score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 9, 512, 1)]       0         \n",
      "_________________________________________________________________\n",
      "split_ts_2 (SplitTS)         (None, 9, 128, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 9, 128, 64)        2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 9, 128, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 9, 128, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 9, 128, 64)        41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 9, 128, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 9, 128, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 9, 128, 64)        41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 9, 128, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 9, 128, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 64, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 4, 64, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 4, 64, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4, 64, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 4, 64, 128)        163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 4, 64, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 4, 64, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 4, 64, 128)        163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 4, 64, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 4, 64, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 2, 32, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 2, 32, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 2, 32, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 2, 32, 256)        655616    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 2, 32, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 2, 32, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 2, 32, 256)        655616    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 2, 32, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 2, 32, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 168)               688296    \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 23)                3887      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 2,831,407\n",
      "Trainable params: 2,828,719\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select samples for XAI methods validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_val = FASTCHARGESequence(X_test, batches_per_epoch=5000, batch_size=256)\n",
    "\n",
    "X, Y = gen_val.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(X, open(\"../data/models/fast_charge/samples.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(Y, open(\"../data/models/fast_charge/targets.pk\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
